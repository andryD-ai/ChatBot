{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qFBRn_Pb8w0j",
        "u4oz62V991tK"
      ],
      "authorship_tag": "ABX9TyPMsVMUt9Kfi+7xeQutlvmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andryD-ai/ChatBot/blob/main/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download dataset and minbpe"
      ],
      "metadata": {
        "id": "qFBRn_Pb8w0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir /content/model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfYJLbxNtHbh",
        "outputId": "3a222e42-1ae8-45a3-8ee7-33e39609732a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/model/\n",
        "%mkdir /content/model/data/\n",
        "%cd /content/model/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9jWNApS9huX",
        "outputId": "b95b4743-16f6-4143-d502-b7af15590280"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model\n",
            "/content/model/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget   https://www.kaggle.com/api/v1/datasets/download/grafstor/simple-dialogs-for-chatbot\n",
        "!unzip /content/model/data/simple-dialogs-for-chatbot\n",
        "!rm -r /content/model/data/simple-dialogs-for-chatbot\n",
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwG_lg-g73X5",
        "outputId": "17f597be-c665-433d-fbc6-a8075227dee6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-28 03:27:18--  https://www.kaggle.com/api/v1/datasets/download/grafstor/simple-dialogs-for-chatbot\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com:443/kaggle-data-sets/715041/1245709/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250428%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250428T032720Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=45a89ed9638a542c5bb33651efe572f569b97a2b01a2791b125763dbdb03f3dd31759630a3707444d69952e34bb8e727b445db91f8add275735c56b8d4e09127c9a1571c9ef6babffa10313e1f82729405e7b92ceb95c8ee2ada8a74ed0799e92bc69f5b1a592798ede87689cf63b06529b4fec1ce0c5bd75c46916a12e6a1f8be2f09e0bc26b5cf7a8cfcac98c44fefb080c6d3e8f6fb900e077b288e6ebbaf6ecf319ea8f9e95609243c482065172d54af67469f23aca797ebe43904a61e0f1a29ce473adba42fa831fb164d84b56a9029ff6d47982269bc5383cf1caa825272e8290b22a6ff63d0c0c65eede4495646caa3b57391dbe6b2daf7c64310c0fd [following]\n",
            "--2025-04-28 03:27:20--  https://storage.googleapis.com/kaggle-data-sets/715041/1245709/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20250428%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250428T032720Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=45a89ed9638a542c5bb33651efe572f569b97a2b01a2791b125763dbdb03f3dd31759630a3707444d69952e34bb8e727b445db91f8add275735c56b8d4e09127c9a1571c9ef6babffa10313e1f82729405e7b92ceb95c8ee2ada8a74ed0799e92bc69f5b1a592798ede87689cf63b06529b4fec1ce0c5bd75c46916a12e6a1f8be2f09e0bc26b5cf7a8cfcac98c44fefb080c6d3e8f6fb900e077b288e6ebbaf6ecf319ea8f9e95609243c482065172d54af67469f23aca797ebe43904a61e0f1a29ce473adba42fa831fb164d84b56a9029ff6d47982269bc5383cf1caa825272e8290b22a6ff63d0c0c65eede4495646caa3b57391dbe6b2daf7c64310c0fd\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.196.207, 74.125.134.207, 74.125.139.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.196.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60740 (59K) [application/zip]\n",
            "Saving to: ‘simple-dialogs-for-chatbot’\n",
            "\n",
            "simple-dialogs-for- 100%[===================>]  59.32K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-04-28 03:27:20 (96.0 MB/s) - ‘simple-dialogs-for-chatbot’ saved [60740/60740]\n",
            "\n",
            "Archive:  /content/model/data/simple-dialogs-for-chatbot\n",
            "  inflating: dialogs.txt             \n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/minbpe.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uFo1W78jqoU",
        "outputId": "4216ff07-ea18-4d8d-dcb7-487d5301d233"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'minbpe'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 217 (delta 103), reused 90 (delta 90), pack-reused 94 (from 2)\u001b[K\n",
            "Receiving objects: 100% (217/217), 332.97 KiB | 3.78 MiB/s, done.\n",
            "Resolving deltas: 100% (130/130), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and fine-tuning data\n"
      ],
      "metadata": {
        "id": "u4oz62V991tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMxKtoIeuN_0",
        "outputId": "159ced5e-6411-4cda-d47e-9fa618a7541c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe7CrgWLlCYD",
        "outputId": "8c330c07-4db6-4994-b623-71357c448be1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from minbpe.minbpe import BasicTokenizer\n",
        "\n",
        "\n",
        "with open(\"/content/model/data/dialogs.txt\", \"r\") as f:\n",
        "    text_sequence = f.read()\n",
        "\n",
        "#Train BPE\n",
        "tokenizer = BasicTokenizer()\n",
        "tokenizer.train(text_sequence, vocab_size=1024)"
      ],
      "metadata": {
        "id": "iZM49qYU-F6N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add special token\n",
        "max_vocab_id = list(tokenizer.vocab.keys())[-1]\n",
        "tokenizer.special_tokens = {\n",
        "    \"<|startoftext|>\": max_vocab_id + 1,\n",
        "    \"<|separator|>\": max_vocab_id + 2,\n",
        "    \"<|endoftext|>\": max_vocab_id + 3,\n",
        "    \"<|unk|>\": max_vocab_id + 4\n",
        "}"
      ],
      "metadata": {
        "id": "NKucly5Xlr6p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/model/data/tokenizer"
      ],
      "metadata": {
        "id": "3iDG8kwGl6pN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save(file_prefix=\"/content/model/data/tokenizer/tokenizer\")"
      ],
      "metadata": {
        "id": "GpjR-BLYl4ZG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from minbpe.minbpe import RegexTokenizer\n",
        "\n",
        "tokenizer = RegexTokenizer()\n",
        "tokenizer.load(model_file=\"/content/model/data/tokenizer/tokenizer.model\")\n"
      ],
      "metadata": {
        "id": "gc2M6Os6pmV8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add special_tokens to dataset and tokenized the sequences\n",
        "\n",
        "file_path = \"/content/model/data/dialogs.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "tab_token = \"\\t\"\n",
        "enter_token = \"\\n\"\n",
        "\n",
        "start_of_text_token = \"<|startoftext|>\"\n",
        "end_of_text_token = \"<|endoftext|>\"\n",
        "separator_token = \"<|separator|>\"\n",
        "\n",
        "tokenized_data = []\n",
        "fine_tuning_dataa =[]\n",
        "for line in lines:\n",
        "  line = line.replace(tab_token, separator_token).strip()\n",
        "  line = line.replace(enter_token, \"\").strip()\n",
        "\n",
        "  #fine-tuning data\n",
        "  fine_tuning_data = f\"{start_of_text_token}{line}{end_of_text_token}\"\n",
        "  fine_tuning_dataa.append(fine_tuning_data)\n",
        "  #tokenized the sequences\n",
        "  tokenized_data.append(tokenizer.encode(fine_tuning_data, allowed_special = \"all\"))\n"
      ],
      "metadata": {
        "id": "Yz6OhHYpmdmS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create train, val data"
      ],
      "metadata": {
        "id": "zorfkTCrT1Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\""
      ],
      "metadata": {
        "id": "_-La9TMu1gNy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train data and val data\n",
        "initial_split_index = int(0.9*len(tokenized_data))\n",
        "\n",
        "train_data = tokenized_data[:initial_split_index]\n",
        "val_data = tokenized_data[initial_split_index:]"
      ],
      "metadata": {
        "id": "9S9SvOMjqCEN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine mess to block_size\n",
        "\n",
        "block_size = 256\n",
        "\n",
        "def merge_conversation_to_block_size(data: list[list[int]], block_size: int):\n",
        "  '''\n",
        "  data: tokenized conversation list\n",
        "  block_size: size of block\n",
        "  '''\n",
        "  max = 0\n",
        "  new_convers = []\n",
        "  cur_conver = []\n",
        "  for cover in data:\n",
        "    if len(cur_conver) + len(cover) <= block_size:\n",
        "      cur_conver.extend(cover)\n",
        "    else:\n",
        "      if cur_conver:\n",
        "        new_convers.append(cur_conver)\n",
        "        if max < len(cur_conver):\n",
        "          max = len(cur_conver)\n",
        "      cur_conver = cover.copy()\n",
        "\n",
        "  if cur_conver:\n",
        "    new_convers.append(cur_conver)\n",
        "  return new_convers\n",
        "\n",
        "train_data = merge_conversation_to_block_size(train_data, block_size)\n",
        "val_data = merge_conversation_to_block_size(val_data, block_size)"
      ],
      "metadata": {
        "id": "6I0ULbzlqsmp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding data\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(3647)\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def padding_data(data: list[list[int]], padding: int) -> torch.Tensor:\n",
        "  '''\n",
        "  data: tokenized conversation list\n",
        "  padding: padding index\n",
        "  '''\n",
        "\n",
        "  tensors = []\n",
        "\n",
        "  for index in range(len(data)):\n",
        "    tensor = torch.tensor(data[index])\n",
        "    padded_tensor = F.pad(\n",
        "        input=tensor,\n",
        "        pad=(0, block_size - len(tensor)),\n",
        "        value=padding\n",
        "    )\n",
        "    tensors.append(padded_tensor)\n",
        "\n",
        "  return torch.stack(tensors)\n",
        "\n",
        "padding_token = -100\n",
        "\n",
        "train_data = padding_data(train_data, padding_token)\n",
        "val_data = padding_data(val_data, padding_token)"
      ],
      "metadata": {
        "id": "JwhdhUQkvKuy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class FineTuningDataset(Dataset):\n",
        "    def __init__(self, data: torch.Tensor, device: torch.device, padding_token: int):\n",
        "        self.data = data  # shape: (num_samples, block_size)\n",
        "        self.device = device\n",
        "        self.padding_token = padding_token\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        sample = self.data[index]\n",
        "        x = sample.to(self.device)\n",
        "        y = sample[1:].to(self.device)\n",
        "        padding_tensor = torch.tensor([self.padding_token], device=self.device)\n",
        "        y = torch.cat((y, padding_tensor))\n",
        "        return x, y\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = FineTuningDataset(\n",
        "    data=train_data,\n",
        "    device=device,\n",
        "    padding_token=padding_token\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = FineTuningDataset(\n",
        "    data=val_data,\n",
        "    device=device,\n",
        "    padding_token=padding_token\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "zQBvYr1Q1XyI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(val_loader))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW5Mm5g04kEp",
        "outputId": "4954a1a0-e0ef-4c32-bad5-f220d176be9e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 256]), torch.Size([32, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer"
      ],
      "metadata": {
        "id": "eS240Uc2UDie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "\n",
        "n_embd = 512\n",
        "n_head = 12\n",
        "block_size = 256\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "ydhTHuz_UIJL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "  '''One head of self-attention'''\n",
        "\n",
        "  def __init__(self, head_size: int) -> None:\n",
        "    super().__init__()\n",
        "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "    # input of size (batch, block_size (time-step), n_embd (Channel))\n",
        "    # output of size (batch, block_size (time-step), head size)\n",
        "    _, T, _ = x.shape\n",
        "    q = self.query(x) # (B,bs,hs)\n",
        "    k = self.key(x)   # (B,bs,hs)\n",
        "    # compute attention scores (\"affinities\")\n",
        "    # (B, bs, hs) @ (B, hs, bs) -> (B, bs, bs)\n",
        "    weights = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "    weights = weights.masked_fill(\n",
        "        self.tril[:T, :T] == 0, float('-inf'))  # (B, bs, bs)\n",
        "    weights = F.softmax(weights, dim=-1)  # (B, bs, bs)\n",
        "    weights = self.dropout(weights)\n",
        "    # perform the weighted aggregation of the values\n",
        "    v = self.value(x)  # (B,bs,hs)\n",
        "    out = weights @ v  # (B, bs, bs) @ (B, bs, hs) -> (B, bs, hs)\n",
        "    return out"
      ],
      "metadata": {
        "id": "HJgoG1c-ioz9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_head: int, head_size: int) -> None:\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_head)])\n",
        "    self.projection = nn.Linear(num_head * head_size, n_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    output = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    output = self.projection(output)\n",
        "    return self.dropout(output)\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "  def __init__(self, num_embd) -> None:\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(num_embd, num_embd * 4),\n",
        "        nn.ReLu(),\n",
        "        nn.Linear(num_embd * 4, num_embd),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, num_head: int, num_embd: int) -> None:\n",
        "    super().__init__()\n",
        "    head_size = num_embd // num_head\n",
        "    self.self_attention = MultiHeadAttention(num_head, head_size)\n",
        "    self.feed_forward = FeedFoward(num_embd)\n",
        "    self.layer_nom1 = nn.LayerNorm(num_embd)\n",
        "    self.layer_nom2 = nn.LayerNorm(num_embd)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    output = x + self.layer_nom1(self.self_attention(x))\n",
        "    output = output + self.layer_nom2(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "cndUdytTrus9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V1WPhb9c-ei1"
      }
    }
  ]
}