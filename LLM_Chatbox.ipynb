{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eS240Uc2UDie"
      ],
      "authorship_tag": "ABX9TyNYuac6mdeviZadEl0iSlmw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andryD-ai/ChatBot/blob/main/LLM_Chatbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download dataset and minbpe"
      ],
      "metadata": {
        "id": "qFBRn_Pb8w0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets"
      ],
      "metadata": {
        "id": "4TqFOwvx7gFG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGSBgxSJEfJj",
        "outputId": "f9b0fd1b-fba3-44a1-c32c-4e690c6fe706"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%mkdir /content/model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfYJLbxNtHbh",
        "outputId": "89896385-a55d-41fc-f536-caacf1cb5b12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/model/\n",
        "%mkdir /content/model/data/\n",
        "%cd /content/model/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9jWNApS9huX",
        "outputId": "4ff017f3-7fbd-4240-8a9a-aa919571964b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model\n",
            "/content/model/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "# # Load the IMDB dataset\n",
        "# imdb_dataset = load_dataset(\"MohammadOthman/mo-customer-support-tweets-945k\")"
      ],
      "metadata": {
        "id": "xkLqM3ho7y6R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Check the dataset structure\n",
        "# print(imdb_dataset)\n",
        "\n",
        "# # Access the training, testing, and validation sets\n",
        "# train_data = imdb_dataset['train']\n",
        "\n",
        "# # View a sample from the training data\n",
        "# print(train_data[0])"
      ],
      "metadata": {
        "id": "XlnF-Idu8Dlo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "\n",
        "# tab_token = \" \\t \"\n",
        "# enter_token = \" \\n\"\n",
        "\n",
        "# chat_data = []\n",
        "\n",
        "# for data in tqdm(train_data):\n",
        "#   chat_data.append(data['input'] + tab_token + data['output'] + enter_token)"
      ],
      "metadata": {
        "id": "7pvSf79A_P0l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/Dataset/Chat_Dataset/mo-customer-support-tweets-945k.txt\"\n",
        "# with open(data_path, \"w\") as f:\n",
        "#   f.write(\" \".join(chat_data))"
      ],
      "metadata": {
        "id": "jNzJZiMPDede"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Small dataset\n",
        "# !wget   https://www.kaggle.com/api/v1/datasets/download/grafstor/simple-dialogs-for-chatbot\n",
        "# !unzip /content/model/data/simple-dialogs-for-chatbot\n",
        "# !rm -r /content/model/data/simple-dialogs-for-chatbot\n",
        "# %cd /content/model/data/"
      ],
      "metadata": {
        "id": "pwG_lg-g73X5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/minbpe.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uFo1W78jqoU",
        "outputId": "6b95882e-c81e-44a0-c568-798381e4cd68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'minbpe'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 217 (delta 102), reused 87 (delta 87), pack-reused 93 (from 2)\u001b[K\n",
            "Receiving objects: 100% (217/217), 335.66 KiB | 1.30 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and fine-tuning data\n"
      ],
      "metadata": {
        "id": "u4oz62V991tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMxKtoIeuN_0",
        "outputId": "46991818-e6ce-4299-ac2f-05f09a459439"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe7CrgWLlCYD",
        "outputId": "cabc6a77-49f7-4259-fd59-cf72e19f73e0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model.data.minbpe.minbpe import BasicTokenizer\n",
        "\n",
        "\n",
        "# with open(data_path, \"r\") as f:\n",
        "#     num_of_charas_to_read = 10000000\n",
        "#     text_sequence = f.read(num_of_charas_to_read)\n",
        "\n",
        "# #Train BPE\n",
        "# tokenizer = BasicTokenizer()\n",
        "# tokenizer.train(text_sequence, vocab_size=16384)"
      ],
      "metadata": {
        "id": "iZM49qYU-F6N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Add special token\n",
        "# max_vocab_id = list(tokenizer.vocab.keys())[-1]\n",
        "# tokenizer.special_tokens = {\n",
        "#     \"<|startoftext|>\": max_vocab_id + 1,\n",
        "#     \"<|separator|>\": max_vocab_id + 2,\n",
        "#     \"<|endoftext|>\": max_vocab_id + 3,\n",
        "#     \"<|unk|>\": max_vocab_id + 4\n",
        "# }"
      ],
      "metadata": {
        "id": "NKucly5Xlr6p"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir /content/model/data/tokenizer"
      ],
      "metadata": {
        "id": "3iDG8kwGl6pN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_tokenizer = \"/content/drive/MyDrive/Dataset/Chat_Dataset/mo-customer-support-tweets-945k_token\"\n",
        "# tokenizer.save(file_prefix=path_tokenizer)"
      ],
      "metadata": {
        "id": "GpjR-BLYl4ZG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.data.minbpe.minbpe import RegexTokenizer\n",
        "\n",
        "path_tokenizer = path_tokenizer + \".model\"\n",
        "\n",
        "tokenizer = RegexTokenizer()\n",
        "tokenizer.load(model_file=path_tokenizer)\n"
      ],
      "metadata": {
        "id": "gc2M6Os6pmV8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vocab_size(tokenizer: BasicTokenizer) -> int:\n",
        "    vocab = tokenizer.vocab\n",
        "    special_tokens = tokenizer.special_tokens\n",
        "\n",
        "    return len(vocab) + len(special_tokens)"
      ],
      "metadata": {
        "id": "lfWyMuDw6oGr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add special_tokens to dataset and tokenized the sequences\n",
        "\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "tab_token = \"\\t\"\n",
        "enter_token = \"\\n\"\n",
        "\n",
        "start_of_text_token = \"<|startoftext|>\"\n",
        "end_of_text_token = \"<|endoftext|>\"\n",
        "separator_token = \"<|separator|>\"\n",
        "\n",
        "tokenized_data = []\n",
        "fine_tuning_dataa =[]\n",
        "for line in lines:\n",
        "  line = line.replace(tab_token, separator_token).strip()\n",
        "  line = line.replace(enter_token, \"\").strip()\n",
        "\n",
        "  #fine-tuning data\n",
        "  fine_tuning_data = f\"{start_of_text_token}{line}{end_of_text_token}\"\n",
        "  fine_tuning_dataa.append(fine_tuning_data)\n",
        "  #tokenized the sequences\n",
        "  tokenized_data.append(tokenizer.encode(fine_tuning_data, allowed_special = \"all\"))\n"
      ],
      "metadata": {
        "id": "Yz6OhHYpmdmS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create train, val data"
      ],
      "metadata": {
        "id": "zorfkTCrT1Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "_-La9TMu1gNy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train data and val data\n",
        "initial_split_index = int(0.8*len(tokenized_data))\n",
        "\n",
        "train_data = tokenized_data[:initial_split_index]\n",
        "val_data = tokenized_data[initial_split_index:]"
      ],
      "metadata": {
        "id": "9S9SvOMjqCEN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine mess to block_size\n",
        "\n",
        "block_size = 256\n",
        "\n",
        "def merge_conversation_to_block_size(data: list[list[int]], block_size: int):\n",
        "  '''\n",
        "  data: tokenized conversation list\n",
        "  block_size: size of block\n",
        "  '''\n",
        "  max = 0\n",
        "  new_convers = []\n",
        "  cur_conver = []\n",
        "  for cover in data:\n",
        "    if len(cur_conver) + len(cover) <= block_size:\n",
        "      cur_conver.extend(cover)\n",
        "    else:\n",
        "      if cur_conver:\n",
        "        new_convers.append(cur_conver)\n",
        "        if max < len(cur_conver):\n",
        "          max = len(cur_conver)\n",
        "      cur_conver = cover.copy()\n",
        "\n",
        "  if cur_conver:\n",
        "    new_convers.append(cur_conver)\n",
        "  return new_convers\n",
        "\n",
        "train_data = merge_conversation_to_block_size(train_data, block_size)\n",
        "val_data = merge_conversation_to_block_size(val_data, block_size)"
      ],
      "metadata": {
        "id": "6I0ULbzlqsmp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding data\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(3647)\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def padding_data(data: list[list[int]], padding: int) -> torch.Tensor:\n",
        "  '''\n",
        "  data: tokenized conversation list\n",
        "  padding: padding index\n",
        "  '''\n",
        "\n",
        "  tensors = []\n",
        "\n",
        "  for index in range(len(data)):\n",
        "    tensor = torch.tensor(data[index])\n",
        "    padded_tensor = F.pad(\n",
        "        input=tensor,\n",
        "        pad=(0, block_size - len(tensor)),\n",
        "        value=padding\n",
        "    )\n",
        "    tensors.append(padded_tensor)\n",
        "\n",
        "  return torch.stack(tensors)\n",
        "\n",
        "padding_token = -100\n",
        "\n",
        "train_data = padding_data(train_data, padding_token)\n",
        "val_data = padding_data(val_data, padding_token)"
      ],
      "metadata": {
        "id": "JwhdhUQkvKuy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class FineTuningDataset(Dataset):\n",
        "    def __init__(self, data: torch.Tensor, device: torch.device, padding_token: int):\n",
        "        self.data = data  # shape: (num_samples, block_size)\n",
        "        self.device = device\n",
        "        self.padding_token = padding_token\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        sample = self.data[index]\n",
        "        x = sample.to(self.device)\n",
        "        y = sample[1:].to(self.device)\n",
        "        padding_tensor = torch.tensor([self.padding_token], device=self.device)\n",
        "        y = torch.cat((y, padding_tensor))\n",
        "        return x, y\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = FineTuningDataset(\n",
        "    data=train_data,\n",
        "    device=device,\n",
        "    padding_token=padding_token\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = FineTuningDataset(\n",
        "    data=val_data,\n",
        "    device=device,\n",
        "    padding_token=padding_token\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "zQBvYr1Q1XyI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(val_loader))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW5Mm5g04kEp",
        "outputId": "a021d2e2-2c13-4d5d-da1b-f5b69323e5ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 256]), torch.Size([32, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformer"
      ],
      "metadata": {
        "id": "eS240Uc2UDie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Head(nn.Module):\n",
        "  '''One head of self-attention'''\n",
        "\n",
        "  def __init__(self, head_size: int) -> None:\n",
        "    super().__init__()\n",
        "    self.query = nn.Linear(num_embd, head_size, bias=False)\n",
        "    self.key = nn.Linear(num_embd, head_size, bias=False)\n",
        "    self.value = nn.Linear(num_embd, head_size, bias=False)\n",
        "    self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
        "    # input of size (batch, block_size (time-step), num_embd (Channel))\n",
        "    # output of size (batch, block_size (time-step), head size)\n",
        "    _, T, _ = x.shape\n",
        "    q = self.query(x) # (B,bs,hs)\n",
        "    k = self.key(x)   # (B,bs,hs)\n",
        "    # compute attention scores (\"affinities\")\n",
        "    # (B, bs, hs) @ (B, hs, bs) -> (B, bs, bs)\n",
        "    weights = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
        "    weights = weights.masked_fill(\n",
        "        self.tril[:T, :T] == 0, float('-inf'))  # (B, bs, bs)\n",
        "    weights = F.softmax(weights, dim=-1)  # (B, bs, bs)\n",
        "    weights = self.dropout(weights)\n",
        "    # perform the weighted aggregation of the values\n",
        "    v = self.value(x)  # (B,bs,hs)\n",
        "    out = weights @ v  # (B, bs, bs) @ (B, bs, hs) -> (B, bs, hs)\n",
        "    return out"
      ],
      "metadata": {
        "id": "HJgoG1c-ioz9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Tuple\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_head: int, head_size: int) -> None:\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_head)])\n",
        "    self.projection = nn.Linear(num_head * head_size, num_embd)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    output = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    output = self.projection(output)\n",
        "    return self.dropout(output)\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "  def __init__(self, num_embd) -> None:\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(num_embd, num_embd * 4),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(num_embd * 4, num_embd),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, num_head: int, num_embd: int) -> None:\n",
        "    super().__init__()\n",
        "    head_size = num_embd // num_head\n",
        "    self.self_attention = MultiHeadAttention(num_head, head_size)\n",
        "    self.feed_forward = FeedFoward(num_embd)\n",
        "    self.layer_nom1 = nn.LayerNorm(num_embd)\n",
        "    self.layer_nom2 = nn.LayerNorm(num_embd)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    output = x + self.layer_nom1(self.self_attention(x))\n",
        "    output = output + self.layer_nom2(self.feed_forward(output))\n",
        "    return output\n",
        "\n",
        "class LLM(nn.Module):\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    self.tokens_embdding = nn.Embedding(vocab_size, num_embd)\n",
        "    self.position_embdding = nn.Embedding(block_size, num_embd)\n",
        "    self.blocks = nn.Sequential(\n",
        "        *[Block(num_head, num_embd) for _ in range(num_layer)]\n",
        "    )\n",
        "    self.layer_nom = nn.LayerNorm(num_embd)\n",
        "    self.last_linear = nn.Linear(num_embd, vocab_size)\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module: nn.Module) -> None:\n",
        "    if isinstance(module, nn.Linear):\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        if module.bias is not None:\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "  def forward(self, input_tokens: torch.Tensor, targets: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
        "\n",
        "    B, T = input_tokens.shape\n",
        "    token_embdding = self.tokens_embdding(input_tokens)\n",
        "    positional_embedding = self.position_embdding(\n",
        "        torch.arange(T, device=device)\n",
        "    )\n",
        "\n",
        "    x = token_embdding + positional_embedding\n",
        "    x = self.blocks(x)\n",
        "    x = self.layer_nom(x)\n",
        "    logits = self.last_linear(x)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, input_tokens: torch.Tensor, max_new_tokens: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "                Generate new tokens given a context.\n",
        "\n",
        "                Args:>ns: Starting token indices of shape (batch_size, sequence_length)\n",
        "                        max_new_tokens: Number of new tokens to generate\n",
        "\n",
        "                Returns:\n",
        "                        Tensor of token indices of shape (batch_size, sequence_length + max_new_tokens)\n",
        "                \"\"\"\n",
        "\n",
        "        # input_tokens is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop input_tokens to the last block_size tokens\n",
        "            cropped_input = input_tokens[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, _ = self(cropped_input)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            input_tokens = torch.cat(\n",
        "                (input_tokens, idx_next), dim=1)  # (B, T+1)\n",
        "        return input_tokens\n"
      ],
      "metadata": {
        "id": "cndUdytTrus9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Traning\n"
      ],
      "metadata": {
        "id": "V1WPhb9c-ei1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "\n",
        "num_embd = 1024\n",
        "num_head = 16\n",
        "block_size = 256\n",
        "dropout = 0.2\n",
        "vocab_size = get_vocab_size(tokenizer)\n",
        "num_layer = 4\n",
        "batch_size = 64\n",
        "\n",
        "model = LLM().to(device)\n",
        "model = torch.compile(model)"
      ],
      "metadata": {
        "id": "xrn9L1tbAQI9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(\n",
        "    model: torch.nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    eval_iters: int\n",
        ") -> Dict[str, float]:\n",
        "    output = {}\n",
        "    model.eval()\n",
        "\n",
        "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            if i >= eval_iters:\n",
        "                break\n",
        "            with torch.no_grad():\n",
        "                _, loss = model(x, y)\n",
        "            losses[i] = loss.item()\n",
        "        output[split] = losses.mean().item()\n",
        "\n",
        "    model.train()\n",
        "    return output"
      ],
      "metadata": {
        "id": "jVigWPm2_zsI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(\n",
        "    model: LLM,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epoch: int,\n",
        "    loss: float,\n",
        "    file_path: str = \"checkpoint.pth\"\n",
        ") -> None:\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "    }\n",
        "    torch.save(checkpoint, file_path)"
      ],
      "metadata": {
        "id": "tTzlAzgU_3pe"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -r /content/model/output/\n",
        "%mkdir /content/model/output/"
      ],
      "metadata": {
        "id": "JkfpkB65Fe2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08d0e1d-fa9e-45d0-b72f-8e5a3ea89ed6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/model/output/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 1\n",
        "eval_interval = 100\n",
        "eval_iters = 200\n",
        "learning_rate = 3e-4\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iteration in range(max_iters):\n",
        "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        # Evaluation\n",
        "        if batch_idx % eval_interval == 0 or batch_idx == len(train_loader) - 1:\n",
        "            losses = estimate_loss(\n",
        "                model=model,\n",
        "                train_loader=train_loader,\n",
        "                val_loader=val_loader,\n",
        "                eval_iters=min(eval_iters, len(val_loader))\n",
        "            )\n",
        "            train_losses.append(losses['train'])\n",
        "            val_losses.append(losses['val'])\n",
        "\n",
        "            print(\n",
        "                f\"iteration {iteration} / step {batch_idx}: \"\n",
        "                f\"train loss {losses['train']:.4f}, \"\n",
        "                f\"val loss {losses['val']:.4f}\"\n",
        "            )\n",
        "\n",
        "        # Training step\n",
        "        logits, loss = model(x_batch, y_batch)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Save checkpoint\n",
        "    save_checkpoint(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        epoch=iteration,\n",
        "        loss=loss.item(),\n",
        "        file_path=f\"/content/model/output/checkpoint_{iteration}.pth\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "DypoDkfU_-w9",
        "outputId": "9f77fc8a-008e-417a-ea55-3a95e22c8e4d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0 / step 0: train loss 6.0345, val loss 6.0373\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3025557d809e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;31m# Restore the dynamic layer stack depth if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-6121bf5644ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tokens, targets)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/aot_autograd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*runtime_args)\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0mfull_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0mfull_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;31m# Just for convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mruntime_wrapper\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             ), torch.enable_grad():\n\u001b[0;32m--> 310\u001b[0;31m                 all_outs = call_func_at_runtime_with_args(\n\u001b[0m\u001b[1;32m    311\u001b[0m                     \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_amp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteal_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/utils.py\u001b[0m in \u001b[0;36mcall_func_at_runtime_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_boxed_call\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# TODO: Please remove soon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/utils.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_boxed_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boxed_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, *deduped_flat_tensor_args)\u001b[0m\n\u001b[1;32m   1583\u001b[0m                 \u001b[0;31m# - Note that donated buffer logic requires (*saved_tensors, *saved_symints) showing up last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 \u001b[0;31m#   in the fw output order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m                 fw_outs = call_func_at_runtime_with_args(\n\u001b[0m\u001b[1;32m   1586\u001b[0m                     \u001b[0mCompiledFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_fw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/utils.py\u001b[0m in \u001b[0;36mcall_func_at_runtime_with_args\u001b[0;34m(f, args, steal_args, disable_amp)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_boxed_call\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# TODO: Please remove soon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(runtime_args)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 )\n\u001b[1;32m    489\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py\u001b[0m in \u001b[0;36minner_fn\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mold_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;31m# Inductor cache DummyModule can return None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_inductor/output_code.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_callable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mAutotuneCacheBundler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torchinductor_root/a6/ca6br36atps5cqmiv5rd3tftmq4de22gam7nj53r7ssx6kw5j4fa.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m  15108\u001b[0m     \u001b[0mbuf723\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty_strided_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  15109\u001b[0m     \u001b[0;31m# Topologically Sorted Source Nodes: [input_11], Original ATen: [aten.addmm]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 15110\u001b[0;31m     \u001b[0mextern_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals_223\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinterpret_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf722\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinterpret_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals_222\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuf723\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  15111\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mprimals_223\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  15112\u001b[0m     \u001b[0mbuf726\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty_strided_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
        "plt.plot(val_losses, label=\"Validation Loss\", marker='o')\n",
        "plt.xlabel(\"Evaluation Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Time\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "aEmV9qu7Fywn",
        "outputId": "e18db018-c10f-40c7-cb89-df6a55f1f1c9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer.encode(\"where are you?\")\n",
        "input_tokens = torch.tensor(\n",
        "    input_tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model.generate(input_tokens=input_tokens, max_new_tokens=100)\n",
        "\n",
        "print(tokenizer.decode(output[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySkXMLSGBG8f",
        "outputId": "e632ad60-cf5b-4bca-ac97-e89e0f14d4ed"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "where are you?oislra�rbo|rV�!riaoniirbr�yn0o\\esise*sisnknit\u0014moaoitkdisg�ifrn�ip�noaisOatua�ihikrsiniooB1hniilhnsrc\n"
          ]
        }
      ]
    }
  ]
}